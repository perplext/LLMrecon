package monitoring

import (
	"fmt"
	"log"
	"sync"
)

// AlertSeverity defines the severity level of an alert
type AlertSeverity string

const (
	// InfoSeverity indicates an informational alert
	InfoSeverity AlertSeverity = "info"
	// WarningSeverity indicates a warning alert
	WarningSeverity AlertSeverity = "warning"
	// ErrorSeverity indicates an error alert
	ErrorSeverity AlertSeverity = "error"
	// CriticalSeverity indicates a critical alert
	CriticalSeverity AlertSeverity = "critical"
)

// AlertRule defines a rule for generating alerts based on metric values
type AlertRule struct {
	// Name of the rule
	Name string
	// Description of the rule
	Description string
	// MetricName is the name of the metric to check
	MetricName string
	// Threshold is the value that triggers the alert
	Threshold float64
	// Operator is the comparison operator (>, <, >=, <=, ==, !=)
	Operator string
	// Severity is the severity of the alert
	Severity AlertSeverity
	// Duration is the minimum duration the condition must be true before alerting
	Duration time.Duration
	// Cooldown is the minimum time between alerts for this rule
	Cooldown time.Duration
	// LastTriggered is the time the rule was last triggered
	LastTriggered time.Time
	// Active indicates if the rule is currently active
	Active bool
}

// Alert represents an alert generated by the system
type Alert struct {
	// ID is a unique identifier for the alert
	ID string
	// Rule is the rule that generated the alert
	Rule *AlertRule
	// Value is the value that triggered the alert
	Value float64
	// Timestamp is the time the alert was generated
	Timestamp time.Time
	// Message is the alert message
	Message string
	// Acknowledged indicates if the alert has been acknowledged
	Acknowledged bool
	// AcknowledgedBy is the entity that acknowledged the alert
	AcknowledgedBy string
	// AcknowledgedAt is the time the alert was acknowledged
	AcknowledgedAt time.Time
}

// AlertHandler is an interface for handling alerts
type AlertHandler interface {
	// HandleAlert handles an alert
	HandleAlert(alert *Alert)
}

// LogAlertHandler is an alert handler that logs alerts
type LogAlertHandler struct {
	Logger *log.Logger
}

// HandleAlert logs the alert
func (h *LogAlertHandler) HandleAlert(alert *Alert) {
	h.Logger.Printf("[%s] %s: %s (value: %.2f)", 
		alert.Rule.Severity, 
		alert.ID, 
		alert.Message, 
		alert.Value)
}

// AlertManager manages alert rules and generates alerts
type AlertManager struct {
	// metricsManager is the metrics manager to use
	metricsManager *MetricsManager
	// rules is a map of rule name to rule
	rules map[string]*AlertRule
	// activeAlerts is a map of alert ID to alert
	activeAlerts map[string]*Alert
	// handlers is a list of alert handlers
	handlers []AlertHandler
	// mutex protects the rules and activeAlerts maps
	mutex sync.RWMutex
	// alertIDCounter is a counter for generating alert IDs
	alertIDCounter int
}

// NewAlertManager creates a new alert manager
func NewAlertManager(metricsManager *MetricsManager) *AlertManager {
	manager := &AlertManager{
		metricsManager: metricsManager,
		rules:          make(map[string]*AlertRule),
		activeAlerts:   make(map[string]*Alert),
		handlers:       make([]AlertHandler, 0),
		alertIDCounter: 0,
	}
	
	// Subscribe to metric updates
	metricsManager.Subscribe(manager)
	
	return manager
}

// AddRule adds a rule to the alert manager
func (m *AlertManager) AddRule(rule *AlertRule) {
	m.mutex.Lock()
	defer m.mutex.Unlock()
	
	m.rules[rule.Name] = rule
}

// RemoveRule removes a rule from the alert manager
func (m *AlertManager) RemoveRule(ruleName string) {
	m.mutex.Lock()
	defer m.mutex.Unlock()
	
	delete(m.rules, ruleName)
}

// GetRule gets a rule by name
func (m *AlertManager) GetRule(ruleName string) (*AlertRule, bool) {
	m.mutex.RLock()
	defer m.mutex.RUnlock()
	
	rule, ok := m.rules[ruleName]
	return rule, ok
}

// GetAllRules returns all rules
func (m *AlertManager) GetAllRules() []*AlertRule {
	m.mutex.RLock()
	defer m.mutex.RUnlock()
	
	rules := make([]*AlertRule, 0, len(m.rules))
	for _, rule := range m.rules {
		rules = append(rules, rule)
	}
	
	return rules
}

// AddHandler adds an alert handler
func (m *AlertManager) AddHandler(handler AlertHandler) {
	m.mutex.Lock()
	defer m.mutex.Unlock()
	
	m.handlers = append(m.handlers, handler)
}

// OnMetricUpdate is called when a metric is updated
func (m *AlertManager) OnMetricUpdate(metric *Metric) {
	m.mutex.Lock()
	defer m.mutex.Unlock()
	
	// Check all rules that apply to this metric
	for _, rule := range m.rules {
		if rule.MetricName == metric.Name && rule.Active {
			// Check if the rule condition is met
			if m.checkRuleCondition(rule, metric.Value) {
				// Check if the cooldown period has passed
				if time.Since(rule.LastTriggered) >= rule.Cooldown {
					// Generate an alert
					m.generateAlert(rule, metric.Value)
					rule.LastTriggered = time.Now()
				}
			}
		}
	}
}

// checkRuleCondition checks if a rule condition is met
func (m *AlertManager) checkRuleCondition(rule *AlertRule, value float64) bool {
	switch rule.Operator {
	case ">":
		return value > rule.Threshold
	case "<":
		return value < rule.Threshold
	case ">=":
		return value >= rule.Threshold
	case "<=":
		return value <= rule.Threshold
	case "==":
		return value == rule.Threshold
	case "!=":
		return value != rule.Threshold
	default:
		return false
	}
}

// generateAlert generates an alert
func (m *AlertManager) generateAlert(rule *AlertRule, value float64) {
	// Generate a unique ID for the alert
	m.alertIDCounter++
	alertID := fmt.Sprintf("alert-%d", m.alertIDCounter)
	
	// Create the alert
	alert := &Alert{
		ID:           alertID,
		Rule:         rule,
		Value:        value,
		Timestamp:    time.Now(),
		Message:      fmt.Sprintf("%s: %s %s %.2f", rule.Name, rule.MetricName, rule.Operator, rule.Threshold),
		Acknowledged: false,
	}
	
	// Add the alert to the active alerts
	m.activeAlerts[alertID] = alert
	
	// Notify all handlers
	for _, handler := range m.handlers {
		handler.HandleAlert(alert)
	}
}

// GetActiveAlerts returns all active alerts
func (m *AlertManager) GetActiveAlerts() []*Alert {
	m.mutex.RLock()
	defer m.mutex.RUnlock()
	
	alerts := make([]*Alert, 0, len(m.activeAlerts))
	for _, alert := range m.activeAlerts {
		alerts = append(alerts, alert)
	}
	
	return alerts
}

// GetAlert gets an alert by ID
func (m *AlertManager) GetAlert(alertID string) (*Alert, bool) {
	m.mutex.RLock()
	defer m.mutex.RUnlock()
	
	alert, ok := m.activeAlerts[alertID]
	return alert, ok
}

// AcknowledgeAlert acknowledges an alert
func (m *AlertManager) AcknowledgeAlert(alertID, acknowledgedBy string) error {
	m.mutex.Lock()
	defer m.mutex.Unlock()
	
	alert, ok := m.activeAlerts[alertID]
	if !ok {
		return fmt.Errorf("alert not found: %s", alertID)
	}
	
	alert.Acknowledged = true
	alert.AcknowledgedBy = acknowledgedBy
	alert.AcknowledgedAt = time.Now()
	
	return nil
}

// ResolveAlert resolves an alert
func (m *AlertManager) ResolveAlert(alertID string) error {
	m.mutex.Lock()
	defer m.mutex.Unlock()
	
	_, ok := m.activeAlerts[alertID]
	if !ok {
		return fmt.Errorf("alert not found: %s", alertID)
	}
	
	delete(m.activeAlerts, alertID)
	
	return nil
}

// AddMemoryAlertRules adds standard memory alert rules
func (m *AlertManager) AddMemoryAlertRules(heapAllocWarningMB, heapAllocCriticalMB float64, cooldown time.Duration) {
	// Convert MB to bytes
	heapAllocWarningBytes := heapAllocWarningMB * 1024 * 1024
	heapAllocCriticalBytes := heapAllocCriticalMB * 1024 * 1024
	
	// Add heap allocation warning rule
	m.AddRule(&AlertRule{
		Name:         "heap-alloc-warning",
		Description:  "Heap allocation exceeds warning threshold",
		MetricName:   "system.memory.heap_alloc",
		Threshold:    heapAllocWarningBytes,
		Operator:     ">",
		Severity:     WarningSeverity,
		Duration:     time.Minute,
		Cooldown:     cooldown,
		LastTriggered: time.Time{},
		Active:       true,
	})
	
	// Add heap allocation critical rule
	m.AddRule(&AlertRule{
		Name:         "heap-alloc-critical",
		Description:  "Heap allocation exceeds critical threshold",
		MetricName:   "system.memory.heap_alloc",
		Threshold:    heapAllocCriticalBytes,
		Operator:     ">",
		Severity:     CriticalSeverity,
		Duration:     time.Minute,
		Cooldown:     cooldown,
		LastTriggered: time.Time{},
		Active:       true,
	})
	
	// Add GC CPU fraction warning rule
	m.AddRule(&AlertRule{
		Name:         "gc-cpu-fraction-warning",
		Description:  "GC CPU fraction exceeds warning threshold",
		MetricName:   "system.gc.cpu_fraction",
		Threshold:    0.1, // 10% of CPU time spent on GC
		Operator:     ">",
		Severity:     WarningSeverity,
		Duration:     time.Minute,
		Cooldown:     cooldown,
		LastTriggered: time.Time{},
		Active:       true,
	})
	
	// Add GC CPU fraction critical rule
	m.AddRule(&AlertRule{
		Name:         "gc-cpu-fraction-critical",
		Description:  "GC CPU fraction exceeds critical threshold",
		MetricName:   "system.gc.cpu_fraction",
		Threshold:    0.25, // 25% of CPU time spent on GC
		Operator:     ">",
		Severity:     CriticalSeverity,
		Duration:     time.Minute,
		Cooldown:     cooldown,
		LastTriggered: time.Time{},
		Active:       true,
	})
}

// AddResourcePoolAlertRules adds alert rules for resource pools
func (m *AlertManager) AddResourcePoolAlertRules(poolUtilizationWarning, poolUtilizationCritical float64, cooldown time.Duration) {
	// Add pool utilization warning rule
	m.AddRule(&AlertRule{
		Name:         "pool-utilization-warning",
		Description:  "Resource pool utilization exceeds warning threshold",
		MetricName:   "resource.pool.utilization",
		Threshold:    poolUtilizationWarning,
		Operator:     ">",
		Severity:     WarningSeverity,
		Duration:     time.Minute,
		Cooldown:     cooldown,
		LastTriggered: time.Time{},
		Active:       true,
	})
	
	// Add pool utilization critical rule
	m.AddRule(&AlertRule{
		Name:         "pool-utilization-critical",
		Description:  "Resource pool utilization exceeds critical threshold",
		MetricName:   "resource.pool.utilization",
		Threshold:    poolUtilizationCritical,
		Operator:     ">",
		Severity:     CriticalSeverity,
		Duration:     time.Minute,
		Cooldown:     cooldown,
		LastTriggered: time.Time{},
		Active:       true,
	})
}

// AddConcurrencyAlertRules adds alert rules for concurrency
func (m *AlertManager) AddConcurrencyAlertRules(queueUtilizationWarning, queueUtilizationCritical float64, cooldown time.Duration) {
	// Add queue utilization warning rule
	m.AddRule(&AlertRule{
		Name:         "queue-utilization-warning",
		Description:  "Task queue utilization exceeds warning threshold",
		MetricName:   "concurrency.queue.utilization",
		Threshold:    queueUtilizationWarning,
		Operator:     ">",
		Severity:     WarningSeverity,
		Duration:     time.Minute,
		Cooldown:     cooldown,
		LastTriggered: time.Time{},
		Active:       true,
	})
	
	// Add queue utilization critical rule
	m.AddRule(&AlertRule{
		Name:         "queue-utilization-critical",
		Description:  "Task queue utilization exceeds critical threshold",
		MetricName:   "concurrency.queue.utilization",
		Threshold:    queueUtilizationCritical,
		Operator:     ">",
		Severity:     CriticalSeverity,
		Duration:     time.Minute,
		Cooldown:     cooldown,
		LastTriggered: time.Time{},
		Active:       true,
	})
	
	// Add worker utilization warning rule
	m.AddRule(&AlertRule{
		Name:         "worker-utilization-warning",
		Description:  "Worker utilization exceeds warning threshold",
		MetricName:   "concurrency.worker.utilization",
		Threshold:    0.8, // 80% worker utilization
		Operator:     ">",
		Severity:     WarningSeverity,
		Duration:     time.Minute,
		Cooldown:     cooldown,
		LastTriggered: time.Time{},
		Active:       true,
	})
	
	// Add worker utilization critical rule
	m.AddRule(&AlertRule{
		Name:         "worker-utilization-critical",
		Description:  "Worker utilization exceeds critical threshold",
		MetricName:   "concurrency.worker.utilization",
		Threshold:    0.95, // 95% worker utilization
		Operator:     ">",
		Severity:     CriticalSeverity,
		Duration:     time.Minute,
		Cooldown:     cooldown,
		LastTriggered: time.Time{},
		Active:       true,
	})
}

// AddExecutionTimeAlertRules adds alert rules for execution time
func (m *AlertManager) AddExecutionTimeAlertRules(executionTimeWarningMs, executionTimeCriticalMs float64, cooldown time.Duration) {
	// Add execution time warning rule
	m.AddRule(&AlertRule{
		Name:         "execution-time-warning",
		Description:  "Template execution time exceeds warning threshold",
		MetricName:   "template.execution.time",
		Threshold:    executionTimeWarningMs,
		Operator:     ">",
		Severity:     WarningSeverity,
		Duration:     time.Minute,
		Cooldown:     cooldown,
		LastTriggered: time.Time{},
		Active:       true,
	})
	
	// Add execution time critical rule
	m.AddRule(&AlertRule{
		Name:         "execution-time-critical",
		Description:  "Template execution time exceeds critical threshold",
		MetricName:   "template.execution.time",
		Threshold:    executionTimeCriticalMs,
		Operator:     ">",
		Severity:     CriticalSeverity,
		Duration:     time.Minute,
		Cooldown:     cooldown,
		LastTriggered: time.Time{},
		Active:       true,
	})
}
