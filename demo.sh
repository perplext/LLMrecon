#!/bin/bash
# LLMrecon Test Harness Demo Script

echo "ğŸ”´ LLMrecon Test Harness Demo"
echo "============================="
echo

# Check if Ollama is running
echo "Checking Ollama status..."
if curl -s http://localhost:11434/api/tags > /dev/null; then
    echo "âœ… Ollama is running"
else
    echo "âŒ Ollama is not running. Please start it with: ollama serve"
    exit 1
fi

echo

# List available models
echo "ğŸ“‹ Available Models:"
python3 llmrecon_harness.py --list-models
echo

# List available templates
echo "ğŸ¯ Available Attack Templates:"
python3 llmrecon_harness.py --list-templates
echo

# Run basic demonstration
echo "ğŸš€ Running Quick Demo (Llama3 + Prompt Injection)..."
echo "This will test Llama3 with prompt injection attacks"
echo

python3 llmrecon_harness.py --models llama3:latest --categories prompt_injection

echo
echo "âœ… Demo completed!"
echo
echo "ğŸ“Š Check the results/ directory for detailed reports"
echo "ğŸ—„ï¸  ML data is stored in data/attacks/"
echo
echo "Next steps:"
echo "  â€¢ Run full test suite: python3 llmrecon_harness.py"
echo "  â€¢ Test multiple models: python3 llmrecon_harness.py --models llama3:latest qwen3:latest"
echo "  â€¢ Add custom templates in templates/ directory"
echo "  â€¢ Check TEST-HARNESS-README.md for detailed usage"